{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Professioanl CUDA programming exercises.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucas-t-reis/CUDA/blob/master/notebooks/Professioanl_CUDA_programming_exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWRgXMDQ6CGr",
        "colab_type": "text"
      },
      "source": [
        "- Checking for Nvidia **CUDA toolkit**\n",
        "- Checking for Nvidia Devices (enabled in Runtime type)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZVpeV9H4jqA",
        "colab_type": "code",
        "outputId": "6c7753f8-bca2-4db7-8f6d-38c38ab2d484",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!which nvcc\n",
        "!ls -l /dev/nv*"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/cuda/bin/nvcc\n",
            "crw-rw-rw- 1 root root 195,   0 Jan  7 21:21 /dev/nvidia0\n",
            "crw-rw-rw- 1 root root 195, 255 Jan  7 21:21 /dev/nvidiactl\n",
            "crw-rw-rw- 1 root root 247,   0 Jan  7 21:21 /dev/nvidia-uvm\n",
            "crw-rw-rw- 1 root root 247,   1 Jan  7 21:21 /dev/nvidia-uvm-tools\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYfNhHmp6nfu",
        "colab_type": "text"
      },
      "source": [
        "### Installing plugin to allow running CUDA C/C++ - by [andreinechaev](https://github.com/andreinechaev)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RftHNio77-o7",
        "colab_type": "code",
        "outputId": "7fb4a9b4-2da1-421d-e45f-5b2754dfe6ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc_plugin"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-eco90dxc\n",
            "  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-eco90dxc\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-cp36-none-any.whl size=4307 sha256=1bd7ab19e865e43a8541354968aabb624386150e86dc868e9058d20fc5ed902e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-f6vba6l9/wheels/10/c2/05/ca241da37bff77d60d31a9174f988109c61ba989e4d4650516\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n",
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43neWLQD-T8u",
        "colab_type": "text"
      },
      "source": [
        "# Hello World - Example 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSJPGpe6-6oT",
        "colab_type": "code",
        "outputId": "10b0d38c-7a62-488c-c00b-10e7acc9c627",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "\n",
        "// __global__ qualifier to denote a function called by CPU and executed by GPU    \n",
        "__global__ void helloWorldGPU() {\n",
        "    \n",
        "    int gpu_tid = threadIdx.x;\n",
        "    printf(\"Hello World from GPU thread %d!\\n\", gpu_tid);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    printf(\"Hello World from CPU!\\n\");\n",
        "    \n",
        "    // Kernel\n",
        "    helloWorldGPU <<< 1,10 >>> ();\n",
        "\n",
        "    cudaDeviceReset();\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello World from CPU!\n",
            "Hello World from GPU thread 0!\n",
            "Hello World from GPU thread 1!\n",
            "Hello World from GPU thread 2!\n",
            "Hello World from GPU thread 3!\n",
            "Hello World from GPU thread 4!\n",
            "Hello World from GPU thread 5!\n",
            "Hello World from GPU thread 6!\n",
            "Hello World from GPU thread 7!\n",
            "Hello World from GPU thread 8!\n",
            "Hello World from GPU thread 9!\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVNQOvk7kS8q",
        "colab_type": "text"
      },
      "source": [
        "## Host based array summation (unfinished)\n",
        "pg.28"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tmpfq5tukdVU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "810a6a6d-79bd-4161-d55f-6776f8a3608e"
      },
      "source": [
        "%%cu\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "#include <string.h>\n",
        "\n",
        "void h_sum(float *a, float *b, float *c, const int N) {\n",
        "    for(int i=0; i<N; i++) \n",
        "        c[i] = a[i] + b[i];\n",
        "}\n",
        "\n",
        "void fillArray(float *arr, int size) {\n",
        "    \n",
        "    // Getting random number based on current time\n",
        "    time_t t;\n",
        "    srand( (unsigned int) time(&t));\n",
        "\n",
        "    for(int i=0; i<size; i++)\n",
        "      arr[i] = (rand()%0xFF)/10.0f; // modulo 255\n",
        "\n",
        "}\n",
        "\n",
        "int main () {\n",
        "    \n",
        "    int n = 1024;\n",
        "    size_t nBytes = n * sizeof(float);\n",
        "\n",
        "\n",
        "    float *h_a, *h_b, *h_c; // h_ stands for host data\n",
        "    float *d_a, *d_b, *d_c; // d_ stands for device data\n",
        "\n",
        "    h_a = (float *) malloc(nBytes);\n",
        "    h_b = (float *) malloc(nBytes);\n",
        "    h_c = (float *) malloc(nBytes);\n",
        "\n",
        "    cudaMalloc( (float**) &d_a, nBytes);\n",
        "    cudaMalloc( (float**) &d_b, nBytes);\n",
        "    cudaMalloc( (float**) &d_c, nBytes);\n",
        "    \n",
        "    fillArray(h_a, n);\n",
        "    fillArray(h_b, n);\n",
        "\n",
        "    cudaMemcpy(d_a, h_a, nBytes, cudaMemcpyHostToDevice); // params (dest, src, total data bytes, direction)\n",
        "    cudaMemcpy(d_b, h_b, nBytes, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Host sum\n",
        "    h_sum(d_a, d_b, d_c, n);\n",
        "\n",
        "\n",
        "    free(h_a);\n",
        "    free(h_b);\n",
        "    free(h_c);\n",
        "\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "    \n",
        "}"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}